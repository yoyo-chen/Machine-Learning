参考资料
[DataWhale 组队学习/数据挖掘基础方法/概率统计/3. 常见分布与假设检验](https://github.com/datawhalechina/team-learning/blob/master/02%20%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%9F%BA%E7%A1%80%E6%96%B9%E6%B3%95/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/3.%20%E5%B8%B8%E8%A7%81%E5%88%86%E5%B8%83%E4%B8%8E%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C.md)

[概率论与数理统计-陈希孺](https://github.com/yoyo-chen/Machine-Learning/blob/master/概率论与数理统计%20-%20陈希孺.pdf) 

[优秀分享](https://blog.csdn.net/wuzhongqiang/article/details/106956844)



#### 1. 一般随机变量

##### 1.1 离散型随机变量

* 概率质量函数 (probability mass function) PMF

* 例：二项分布，泊松分布

##### 1.2 连续型随机变量

* 概率密度函数 (probability density function) PDF

* 累积分布函数 (cumulative distribution function) CDF 

* 例：均匀分布，正态分布，指数分布



#### 2. 常见分布

##### 2.1 离散型分布

* 二项分布  $B(n, p)$

  在n次试验中，单次试验成功率为$p$，失败率$q=1-p$，则成功$i$次的概率为，
  $$
  p_i=b(i;n,p)=C_n^ip^i(1-p)^{n-i}, i=0, 1, ..., n
  $$
  
* 泊松分布  $P(\lambda)$

  【例】一定时间内某交通路口所发生的事故个数。

  设所观察的这段时间为 [0,1)，取一个很大的自然数n，把时间段[0,1)分为等长的$n$段。

   假设：

  1. 每段时间足够短，只可能发生一个事故，且发生一个事故的概率为$\frac{\lambda}{n}$。
  2. 各段时间内是否发生事故是独立的。

  事故数$X$可视为在$n$个小段内有事故的时间段个数，服从二项分布$B(n,\frac{\lambda}{n})$ ，于是
  $$
  P(X=i)=C_n^i(\frac{\lambda}{n})^i(1-\frac{\lambda}{n})^{n-1}
  $$
  当$n$取极限时，就得到确切的答案。当$n\rightarrow\infty$时，
  
  $$
  \frac{C_n^i}{n^i}\rightarrow \frac{1}{i!}
  $$

  $$
  (\frac{\lambda}{n})^n\rightarrow e^{-\lambda}
  $$

  由此得出
  $$
  P(X=i)=e^{-\lambda} \frac{\lambda^i}{i!} 
  $$

  泊松分布的另一个例子[每天卖多少只馒头](https://blog.csdn.net/ccnt_2012/article/details/81114920)



* 二项分布，泊松分布，正态分布的关系

   若 $X \sim B(n, p)$，其中$n$很大，$p$很小而$np=\lambda$不太大时，则$X$的分布接近于泊松分布。

  $\rightarrow$ 可以将较难计算的二项分布转化为泊松分布计算。

  

* 其他离散型分布

  a. 几何分布

  考虑独立重复试验，几何分布描述的是经过k次试验才首次获得成功的概率，假定每次成功率为p，
  $$
  P\lbrace X= k \rbrace = {(1-p)}^{k-1} p
  $$

  b. 负二项分布

  考虑独立重复试验，负二项分布描述的是试验一直进行到成功r次的概率，假定每次成功率为p，
  $$
  P\lbrace X= n \rbrace = C_{n-1}^{r-1} p^r {(1-p)}^{n-r}
  $$
  
  c. 超几何分布
  
  超几何分布描述的是在一个总数为N的总体中进行有放回地抽样，其中在总体中k个元素属于一组，剩余N-k个元素属于另一组，假定从总体中抽取n次，其中包含x个第一组的概率为
$$
P\lbrace X= n \rbrace = \frac {C_{k}^{x} C_{N-k}^{n-x}} {C_{N}^{n}}
$$



##### 2.2 连续型分布

* 均匀分布  $R(a, b)$
  $$
  f(x)=\begin{cases}\frac {1} {b-a} ,  &  a \leq x  \leq b \\0, & others\end{cases}
  $$

* 正态分布 $N(\mu, \sigma^2)$
  $$
  f(x)=\frac{1}{\sqrt{2π}\sigma}e^{\frac{-(x-u)^2}{2\sigma^2}}
  $$

* **指数分布**  $E(\lambda)$
  $$
  f(x)=\begin{cases}λe^{-λx} ,  &   x  > 0 \\0, & x \leq 0\end{cases}
  $$
  
  $$
  F(x)=\begin{cases}1-e^{-λx} ,  &   x  > 0 \\0, & x \leq 0\end{cases}
  $$
  
  指数分布看起来很有趣！
  
  【例】寿命分布
  
  设一种大批生产的电子元件的寿命$X$是随机变量，以$F$记$X$的分布函数。
  
  假设元件不发生老化，就是说，元件在时刻$x$尚能正常工作的条件下，其失效率总为常数$\lambda$。失效率是指单位长度时间内失效的概率（瞬时失效率）。上述假设如下式所示，
  $$
  P(x \leq X \leq x+h | X >x )/h = \lambda, h \rightarrow 0
  $$
  此式解释如下：元件在时刻$x$时能够正常工作，表示其寿命大于$x$，即$X>x$。在$x$处，长为$h$的时间段内失效，即$x\leq X \leq x+h$。把这个条件概率除以时间段之长$h$，即得在$x$时刻得平均失效率。再令$h\rightarrow0$，得瞬时失效率，按假定，它应为常数$\lambda$。
  
  根据定义可知，
  $$
  P(X>x) = 1-F(x)
  $$
  
  $$
  \{X>x\}\{x\leq X \leq x+h\}=\{x<X\leq x+h\}
  $$
  
  因此，
  $$
  P(x\leq X\leq x+h | X>x)/h
  $$
  
  $$
  =P(x<X\leq x+h)/(h(1-F(x)))
  $$
  
  $$
  =[(F(x+h)-F(x))/h]/(1-F(x))
  $$
  
  $$
  \rightarrow F'(x)/(1-F(x))=\lambda
  $$
  
  这个微分方程的通解为$F(x)=1-Ce^{\lambda x}$（当$x>0$。$x\leq0$时$F(x)$为0）。常数$C$可用初始条件$F(0)=0$（因为$F(0)=P(X\leq 0)$，而寿命$\leq 0$的概率为0）定出为1，这样就得到上述的分布函数。
  
  
  
  梳理一下指数分布中的各个概率：元件的瞬时失效率是常数$\lambda$，从当前时间点经过时间$x$失效的概率是$f(x)$，寿命短于$x$的概率是$F(x)$。
  
  
  
  关于指数分布还有一个有趣的性质的是指数分布是无记忆性的，假定在等候事件发生的过程中已经过了一些时间，此时距离下一次事件发生的时间间隔的分布情况和最开始是完全一样的，就好像中间等候的那一段时间完全没有发生一样，也不会对结果有任何影响（因为没有考虑“老化”，也就是说，该事件在任意一个瞬时发生的概率是一个常数），用数学语言来表述是
  $$
  P\{X>s+t | X> t\} =P\{X>s\}
  $$
  指数分布的另一个例子：[卖出馒头的时间间隔](https://blog.csdn.net/ccnt_2012/article/details/89875865)
  
  
  
* 其他连续型分布

  a. $\Gamma$分布

  常用来描述某个事件发生n次的等待时间的分布。

  

  **b. 威布尔分布**

  指数分布的例子里没有考虑元件的老化，威布尔分布则可以考虑老化的影响。此处的失效率不是常数，而是一个$x$的增函数，$\lambda x^m (\lambda>0, m>0)$。根据和指数分布相同的推导过程可得
  $$
  F'(x)/(1-F(x))=\lambda x^m
  $$
  结合初始条件$F(0)=0$，得出，
  $$
  F(x)=1-e^{(-\lambda/m+1) x^{m+1}}
  $$
  取$a=m+1(a>1)$，并把$\lambda/(m+1)$记为$\lambda$，得出
  $$
  F(x)=1-e^{(-\lambda) x^a}
  $$
  威布尔分布和指数分布在可靠性统计分析中占重要地位。

  

##### 2.3 常见分布的均值和方差汇总 （见DataWhale参考资料）

##### 2.4 Python代码实战 （见DataWhale参考资料）

* 生成一组符合特定分布的随机数

* 计算统计分布的PMF和PDF

* 计算统计分布的CDF

  以上三条都很easy，一行代码就可以搞定。

* 统计分布可视化

  这个用的是sns.distplot()

  【例】二项分布

  ```python
  t = stats.binom.rvs(10,0.5,size=10000) # B(10,0.5)随机抽样10000次
  
  sns.distplot(t,bins=10,hist_kws={'density':True}, kde=False,label = 'Distplot from 10000 samples')
  ```



#### 3. 假设检验

##### 3.1 问题提法和基本概念

<font color = blue>注：3.1节中的各种名词很可能给你一种莫名其妙的感觉。先认识一下就好，3.2节将结合具体的例子给出直观的解释。</font>



###### 3.1.1 问题提法

还是2.2节中元件寿命服从指数分布的例子，现在的问题是，通过对抽出的若干个元件进行测试所得的数据，来判断“元件平均寿命不小于5000小时”是否成立。用统计学的语言表述如下：



1. 有一个总体，即一批元件的寿命，我们假设该总体的分布服从指数分布，该分布包含了一个未知参数$\lambda$

2. 从该总体中抽出样本$X_1,\cdots,X_n$，即抽出的那$n$个元件测试出的寿命。

3. 现在有一个需要**判断**的**命题**：“元件平均寿命不小于5000小时”，即“$\frac{1}{\lambda}\geq5000$”。它把参数$\lambda$所有可能取得值$0<\lambda<\infty$分成两部分：$H_0=\{\lambda: \lambda \leq 1/5000\}$，$H_1=\{\lambda: \lambda > 1/5000\}$。$H_0$内的$\lambda$使上述命题成立，$H_1$内的$\lambda$使上述命题不成立。因此该命题可记为：“$\lambda$属于$H_0$”，或写为“$\lambda \in H_0$”，或只写为$H_0$。

4. 任务是利用所获得的样本，去判断命题是否成立。

   

- 在数理统计学上，将上述**命题**称为**假设**，**判断**称为**检验**。注意检验兼具动词和名词属性，动词指判断全过程的操作，名词指判断准则，通常记为$\Phi$。
- $H_0$：原假设，$H_1$：对立假设（全体：$\lambda > 1/5000$，或特殊情况：$\lambda = 2/5000$）。
- 检验统计量$\overline X$：检验一个假设时所使用的统计量，例子中为元件寿命的均值。
- 接受域$A$：使原假设被接受的样本所在的区域。
- 否定域（拒绝域、临界域）$R$：使原假设被否定的样本所在的区域。
- 临界值：划分接受域与否定域的统计量的值。
- 简单假设：单参数。复合假设：多参数。



###### 3.1.2 功效函数 $\beta_\Phi$

- 原假设被否定的概率



###### 3.1.3 两类错误、检验的水平

- 两类错误：

  1. $H_0$正确，但被否定了

  2. $H_0$不正确，但被接受了

  为什么要区分这两个看起来相同的错误？3.2.1节中将结合具体例子解释。

- 检验的水平：

  选择一个检验时，要使其功效函数在$H_0$上尽量小而在$H_1$上尽量大。

  但这两方面的要求是矛盾的（怎么矛盾了也会在3.2.1节中解释）。可以通过“**保一望二**”原则解决这个问题：

  先保证第一类错误的概率不超过某指定值$\alpha$（通常较小，最常用的是$\alpha=0.05$和$0.01$，有时也用到$0.001，0.1，$以至$0.2$等值），再在这限制下，使第二类错误概率尽可能小。
  $$
  \beta_\Phi(\theta_1,\cdots,\theta_k)\leq \alpha, 对任何(\theta_1,\cdots,\theta_k)\in H_0
  $$
  
  
  $\alpha$为常数，$0\leq \alpha \leq 1$。称$\Phi$为$H_0$的一个水平$\alpha$的检验，或者说，检验$\Phi$的水平为$\alpha$，检验$\Phi$有水平$\alpha$。
  
  只要可能，尽量找最小的$\alpha$。

  ```tex
注：以上所述“固定（或限制）第一类错误概率的原则”是一种目前被广泛采用的做法。在多数假设检验问题中，第一类错误被认为更有害，更需要控制。但也并非绝对，有时第二类错误的危害更大，因此“固定（或限制）第一类错误概率的原则”也并非绝对，可根据具体情况的需要变通。
  ```



###### 3.1.4 一致最优检验

若对任意其他一个水平$\alpha$的检验$g$，必有
$$
\beta_\Phi(\theta_1,\cdots,\theta_k)\geq \beta_g(\theta_1,\cdots,\theta_k), 对任何(\theta_1,\cdots,\theta_k)\in H_1
$$
则称$\Phi$是假设检验问题$H_0:H_1$的一个水平$\alpha$的一致最优检验。

```latex
注1：上述定义换句话说，就是在一切其第一类错误概率不超过$\alpha$的检测中，第二类错误的概率处处达到最小者（功效函数在对立假设上处处达到最大）。
注2：一致最优检验要求“处处”成立，很难满足，一般对总体分布有一定限制时才存在。
```



##### 3.2 重要参数检验

###### 3.2.1 正态总体均值的检验

<font color = blue>注：这个例子在描述过程中将对3.1节中的大部分名词给出直观解释，虽然有点长，但分析过程非常精彩。吃透这个例子，参数检验这一块就算是入门了。</font>

设$X_1,\cdots,X_n$是自正态总体$N(\theta,\sigma^2)$中抽出的样本，下面来讨论有关均值$\theta$的假设检验问题。在应用上常见的形式有以下三种，这里$\theta_0$是一个给定的数。

　　①　$H_0: \theta \geq \theta_0, H_1: \theta < \theta_0$

　　②　$H_0': \theta \leq \theta_0, H_1': \theta > \theta_0$

　　③　$H_0'': \theta = \theta_0, H_1'': \theta \neq \theta_0$

方差已知还是未知将对结果有很大影响，先按最简单的情况，方差已知，来讨论。

先考虑检验问题①，记样本均值为$\overline{X}$，$\overline{X}$是$\theta$的估计。故$\overline{X}$越大，与原假设越符合。写成检验的形式如下：
$$
\Phi:当\overline{X}\geq C 时接受原假设H_0，\overline{X}< C 时否定H_0
$$
接下来将进行一系列骚操作，为了防止迷失自我，先回顾一下3.1.3节中的**保一望二原则：先保证第一类错误（原假设正确，但被否定）的概率不超过某指定值$\alpha$（检验水平），再在这限制下，使第二类错误（原假设错误，但被接受）概率尽可能小。**

所以第一步是考虑如何**保一**。先把 “原假设被否定的概率不超过$\alpha$” 写成概率的形式：
$$
P(H_0被否定)\leq \alpha
$$
$H_0$被否定的概率即3.1.2节中定义的功效函数 $\beta_\Phi$

结合刚刚构造好的检验形式，可以将$H_0$被否定的概率记为，
$$
\beta_\Phi(\theta)=P_\theta(\overline{X}<C)
$$
又因为总体$\sim N(\theta,\sigma^2)\rightarrow, \sqrt{n}(\overline{X}-\theta)/\sigma \sim N(0,1)$，有
$$
\beta_\Phi(\theta)=P_\theta(\sqrt{n}(\overline{X}-\theta)/\sigma<\sqrt{n}(C-\theta)/\sigma)
$$

以$\Phi$记$\sqrt{n}(\overline{X}-\theta)/\sigma$的分布函数，有
$$
\beta_\Phi(\theta)=\Phi(\sqrt{n}(C-\theta)/\sigma)\leq \alpha
$$

因为分布函数本身是非降的（这一点要牢记，后面将反复使用），通过上式可知，$\theta$越大，分布函数$\Phi$的值越小。若想要上式在$\theta \geq \theta_0$<font color = blue>(注意，考虑“保一”时，以原假设正确为前提，即$\theta \geq \theta_0$)</font>时成立，只要$\beta_\Phi(\theta_0)=\alpha$即可，
$$
\beta_\Phi(\theta_0)=\Phi(\sqrt{n}(C-\theta_0)/\sigma)= \alpha
$$
由上式便可得出$C$，
$$
C=\theta_0-\sigma u_\alpha / \sqrt{n}
$$
$C$是一个略小于$\theta_0$的数，可以看出，检验条件比原假设宽松。

推导过程略，需要用到下面几个式子，
$$
\Phi(u_\alpha)=1-\alpha; 
\Phi(u_{1-\alpha})=\alpha;
u_{1-\alpha}=-u_\alpha;
(0<u_\alpha<1, -1<u_{1-\alpha}<0)
$$
将$C$代入$\beta_\Phi(\theta)$，得到功效函数的完成版如下，
$$
\beta_\Phi(\theta)=\Phi(\sqrt{n}(\theta_0-\theta)/\sigma-u_\alpha)
$$
好了，这个功效函数就可以确保“保一望二”里的“保一”了，即原假设正确、但被否定的概率不超过$\alpha$。

-------

建议在这里休息一下，给大脑降降温。

-----



下面让我们看看如何考虑“望二”，即犯第二类错误（原假设错误、但被接受）的概率尽可能小。

<font color = blue>(注意，考虑望二时，以原假设错误为前提，即$\theta < \theta_0$。)</font>

仔细观察刚刚得到的功效函数完成版，重写一遍如下，
$$
\beta_\Phi(\theta)=\Phi(\sqrt{n}(\theta_0-\theta)/\sigma-u_\alpha)
$$
若$\theta < \theta_0$，则可以得出以下几条结论：

(a). $\theta$越小，$\beta_\Phi(\theta)$越大，原假设被否定的概率越大，因为原假设在这里是错的，所以$\beta_\Phi(\theta)$越大越好。可是当$\theta$很接近$\theta_0$时，$\beta_\Phi(\theta)\thickapprox \alpha$，$\alpha$一般是个很小的数，因此此时接受错误的原假设的概率为$1-\beta_\Phi(\theta)\thickapprox 1-\alpha$很接近1，这个是不OK的。

(b). 对固定的$\theta < \theta_0$，$\sigma$越大，$\beta_\Phi(\theta)$越小。也就是说，误差越大，接受错误的原假设的概率越大。

(c). $\alpha$越大，$u_\alpha$越小，$\beta_\Phi(\theta)$越大。也就是说，能容许的第一类错误的概率越大，犯第二类错误的概率越小。<font color = blue>这里可以看出两种错误的矛盾关系。</font>

只通过观察能得出的结论快被榨干了，那要想控制犯第二类错误的概率，该怎么办呢？

设犯第二类错误的概率小于指定值$\beta$（$\beta$是一个大于0的较小的数），即
$$
\beta_\Phi(\theta)\geq 1-\beta, \theta < \theta_0
$$
但是，由上文的结论(a)已知，当$\theta$很接近$\theta_0$时，$\beta_\Phi(\theta)\thickapprox \alpha$，$\alpha$一般是个很小的数，$\beta$也是一个较小的数，两全不能齐美，上式的要求是无法达到的。只能放松一点，要求对某个指定的$\theta_1 < \theta_0$，有
$$
\beta_\Phi(\theta)\geq 1-\beta, \theta < \theta_1
$$
$\theta$越小，$\beta_\Phi(\theta)$越大，因此只需满足
$$
\beta_\Phi(\theta_1)\geq 1-\beta
$$

$$
\beta_\Phi(\theta_1)=\Phi(\sqrt{n}(\theta_0-\theta_1)/\sigma-u_\alpha)\geq 1-\beta
$$

$$
\sqrt{n}(\theta_0-\theta_1)/\sigma-u_\alpha\geq u_\beta
$$

$$
n\geq \sigma^2(u_\alpha+u_\beta)^2/(\theta_0-\theta_1)^2
$$

就是说，样本大小至少应达到上式右边那么大，才能保证$\theta < \theta_1$时，犯第二类错误的概率小于$\beta$。

神奇不，最后竟然推出来了一个样本大小的下限值。

式中的$n$与$\sigma^2$成正比，即方差越大，为达到一定的分辨率，所需要的样本数也越多。

好了，现在是不是明白了为什么要分两类错误，为什么错误一和错误二不能兼顾，以及“保一望二”是如何操作的了？回答不出来的话，回去重看一遍。

简单点讲，之所以有以上种种麻烦，就是因为我们在检验问题里设定的临界值C，和假设里的$\theta_0$不是完全相等的，是更宽松的限值（例如原假设为$\theta \geq \theta_0$，那么$C<\theta_0$），而$\theta_0$严格划分了原假设和对立假设。一个模糊，一个清晰，就会产生矛盾。在$\theta_0$附近，估计值比$\theta_0$小还是比$\theta_0$大的概率差不多，在这个暧昧的区间上，想要一侧概率很小而另一侧概率很大是不可能的，即原假设为真时拒绝的概率很小而原假设为假时拒绝的概率很大是无法实现的。（解释待改善）

---

缓一下，接下来分析检验问题②

---

检验问题 ②　$H_0': \theta \leq \theta_0, H_1': \theta > \theta_0$

$\overline{X}$越小，与原假设越符合。仿照上述讨论，写成检验的形式如下：
$$
\Phi':当\overline{X}\leq \theta_0+\sigma u_\alpha / \sqrt{n} 时接受H_0'，不然就否定H_0'
$$
功效函数为：
$$
\beta_\Phi'(\theta)=1-\Phi(\sqrt{n}(\theta_0-\theta)/\sigma+u_\alpha)
$$
若选定$\theta_1 > \theta_0$，要求$\beta_\Phi'(\theta)\geq 1-\beta, \theta \geq \theta_1$，则得最小所需样本大小$n$与检验问题①中的计算公式相同。

---

检验问题②完了，下面让我们分析检验问题①和②的区别，解释设定原假设时的“倾向性”。

---

检验问题① $H_0: \theta \geq \theta_0, H_1: \theta < \theta_0$
$$
\Phi':当\overline{X}\geq \theta_0-\sigma u_\alpha / \sqrt{n} 时接受H_0'，不然就否定H_0'
$$
检验问题② $H_0': \theta \leq \theta_0, H_1': \theta > \theta_0$
$$
\Phi':当\overline{X}\leq \theta_0+\sigma u_\alpha / \sqrt{n} 时接受H_0'，不然就否定H_0'
$$
放在一起看一下，发现什么问题了没有？

问题就是，这两个检验问题的原假设相反，但接受域有重合，重合的部分如下，
$$
\theta_0-\sigma u_\alpha / \sqrt{n} \leq \overline{X} \leq \theta_0+\sigma u_\alpha / \sqrt{n}
$$
也就是说，如果估计值处在上述区间，那么按检验问题①的提法，应接受$\theta \geq \theta_0$；然而按检验问题②的提法，则应接受$\theta \leq \theta_0$。

为什么会出现看似矛盾的结果？

这是因为统计推断并不是“非此即彼”的逻辑，在问题的提法上具有“倾向性”。

简单来说，就是原假设中的问题，我们倾向于希望它是正确的，需要较强的证据才能推翻它。

例如，某商店经常从某工厂进货，该厂过去的产品质量总的说是好的，商店同意把$\theta \geq \theta_0$做为原假设，并选定一个较低的检验水平$\alpha$，这保证了优质的批($\theta \geq \theta_0$)只以很低的概率$\alpha$被拒收，而非优质的批($\theta < \theta_0$)仍能以不很小的概率被接受。要有较强的证据（即$\overline{X}< \theta_0-\sigma u_\alpha / \sqrt{n}$）才否定$\theta \geq \theta_0$

反之，如果该厂过去一段时间产品质量并不好，商店就可以选择$\theta \leq \theta_0$做为原假设，并选定一个较低的检验水平$\alpha$，这表明商店要求有较强的证据（即$\overline{X}> \theta_0+\sigma u_\alpha / \sqrt{n}$）才否定$\theta \leq \theta_0$，相信这批产品质量为优。

<font color=blue>注：否定原假设并不等于接受其反命题，而只能说没有足够的证据证明原假设为真。</font>

---

终于到检验问题③了

---

检验问题③　$H_0'': \theta = \theta_0, H_1'': \theta \neq \theta_0$

其检验如下，
$$
\Phi'':当\theta_0-\sigma u_{\alpha/2} / \sqrt{n} \leq \overline{X} \leq \theta_0+\sigma u_{\alpha/2} / \sqrt{n} 时接受H_0''，不然就否定H_0''
$$

---

可以证明，检验$\Phi$和$\Phi'$分别是检验问题①和②的水平的一致最优检验，而检验问题③的一致最优检验不存在。

关于方差已知时，三个检验问题的讨论在此收尾。后面的内容将只简略介绍，具体内容见陈老师的《概率论与数理统计》

---

方差未知时，问题在于常数$C$依赖于未知的$\sigma$，无法确定。可以用方差的估计值$S$代替。

用$S$代替$\sigma$后，正态分布变为自由度$n-1$的$t$分布，常数$u_\alpha$也改为$t_{n-1}(\alpha)$，得到三个问题的检验如下：

检验问题①，
$$
\Phi:当\sqrt{n}(\overline{X}-\theta_0)/S \geq -t_{n-1}(\alpha) 时接受H_0，不然就否定H_0
$$
检验问题②，
$$
\Phi':当\sqrt{n}(\overline{X}-\theta_0)/S \leq t_{n-1}(\alpha) 时接受H_0'，不然就否定H_0'
$$
检验问题③，
$$
\Phi'':当|\sqrt{n}(\overline{X}-\theta_0)/S |\leq t_{n-1}(\alpha/2) 时接受H_0''，不然就否定H_0''
$$
<font color=blue>这三个检验统称为$t$检验，是应用上最重要的检验之一。</font>

很遗憾，因为方差未知，这些检验的性质也较为复杂，无法像方差已知时那样得出样本下限值，单侧检验也不是一致最优的（除非$\alpha>1/2$）。现实世界太复杂，哎。



###### 3.2.2 两个正态总体均值差的检验

两样本$t$检验

显著性检验：原假设在水平$\alpha$上被否定时，我们说估计量达到了“显著性”，即与原假设的差异如此显著，已不能仅由随机性来解释，以至于可以否定原假设。任何一个检验都可以理解为显著性检验，但这个词最常用在关于某种效应或差异是否存在的问题。

###### 3.2.3 正态分布方差的检验

和正态分布均值的检验相比，方差的检验在应用上较少，但也有一些应用。例如一种仪器或测定方法的精度。方差比检验可以用于检验两个方差相等的假定（如在两样本t检验中）是否合理。

###### 3.2.4 指数分布参数的检验

可靠性分析中的一个基础性分布

###### 3.2.5 二项分布参数$p$的检验

产品抽样验收

符号检验（民意测试） 

非参数检验

###### 3.2.6 泊松分布参数$\lambda$的检验

定时截尾寿命检验

###### 3.2.7 大样本检验

不知道检验统计量的确切分布，使用极限分布，确定临界值$C$。

统计方法的大小样本之分，不在于样本大小$n$多大（无清楚界线），而全看其是否使用有关变量的极限分布。

###### 3.2.9 贝叶斯方法

如已经选定了先验分布，则在有了样本之后，分别算出原假设和对立假设的条件概率。若前者大于后者，则接受原假设；若后者大于前者，则否定原假设；若两者相等，则可让其悬而不决。



##### 3.3 拟合优度检验

检验观察到的一批数据是否与某种理论分布符合。

卡方检验法（$\chi^2$检验法）



###### 3.3.1 理论分布完全已知且只取有限个值的情况

皮尔逊拟合优度$\chi^2$统计量：
$$
Z=\sum(理论值-经验值)^2/理论值
$$
**定理3.1** 如果原假设$H_0$成立，则在样本大小$n \rightarrow \infty$时，$Z$的分布趋向于自由度$k-1$的$\chi^2$分布，即$\chi_{k-1}^2$。

检验：
$$
\phi: 当Z\leq \chi_{k-1}^2(\alpha)时接受H_0,不然就否定H_0
$$
假定根据一组具体数据算出的$Z$值为$Z_0$，在$H_0$成立的前提下，任意一组数据产生等于或大于$Z_0$的差异的概率：
$$
p(Z_0)=P(Z\geq Z_0|H_0)\thickapprox 1-K_{k-1}(Z_0)
$$
这个概率陈伟数据对理论分布的**“拟合优度”**

拟合优度越大，就表示数据与理论之间符合度越高。

注意，试验次数极大时，微小的差异会被放大，统计上的显著性并不等同于实用上的重要性。假设检验的结果含义必须结合其他方面的考虑（样本大小，估计值等），才能得到更合理的解释。



###### 3.3.2 理论分布只含有限个值但不完全已知的情况

理论分布部分已知，包含未知参数$\theta$。需要利用数据对参数值做估计。

**定理3.2** 在一定条件下，若原假设成立，则当样本大小$n \rightarrow \infty$时，$Z$的分布趋向于自由度$k-1-r$的$\chi^2$分布，即$\chi_{k-1-r}^2$。

$r$为需要估计的参数个数。



###### 3.3.3 对列联表的应用

列联表是一种按两个属性做双向分类的表。

例如，一群人按男女（属性A）和是否色盲（属性B）分类，目的是考察性别对色盲有无影响。
$$
Z=\sum\sum(nn_{ij}-n_{i*}n_{*j})^2/(nn_{i*}n_{*j})
$$
齐一性检验：不同的总体的分布是否一致。

独立性检验：两个属性有无关联存在。



###### 3.3.4 总体分布为一般分布的情形

检验方法：通过区间划分把它转化为已讨论过（3.3.2节）的情况。



##### 3.4 基本步骤（见DataWhale参考资料）



##### 3.5 统计量的选择

选择合适的统计量是进行假设检验的关键步骤，最常用的统计检验包括回归检验(regression test)，比较检验(comparison test)和关联检验(correlation test)三类。

**回归检验**

回归检验适用于预测变量是数值型的情况，根据预测变量的数量和结果变量的类型又分为以下几种。

|              |    预测变量    | 结果变量 |
| :----------: | :------------: | :------: |
| 简单线性回归 | 单个，连续数值 | 连续数值 |
| 多重线性回归 | 多个，连续数值 | 连续数值 |
| Logistic回归 |    连续数值    | 二元类别 |

**比较检验**

比较检验适用于预测变量是类别型，结果变量是数值型的情况，根据预测变量的分组数量和结果变量的数量又可以分为以下几种。

|                    |     预测变量     |       结果变量       |
| :----------------: | :--------------: | :------------------: |
|   Paired t-test    |    两组，类别    | 组来自同一总体，数值 |
| Independent t-test |    两组，类别    | 组来自不同总体，数值 |
|       ANOVA        | 两组及以上，类别 |      单个，数值      |
|       MANOVA       | 两组及以上，类别 |   两个及以上，数值   |

**关联检验**

关联检验常用的只有卡方检验一种，适用于预测变量和结果变量均为类别型的情况。

**非参数检验**

此外，由于一般来说上述参数检验都需满足一些前提条件，样本之间独立，不同组的组内方差近似和数据满足正态性，所以当这些条件不满足的时候，我们可以尝试用非参数检验来代替参数检验。

|        非参数检验         | 用于替代的参数检验 |
| :-----------------------: | :----------------: |
|         Spearman          |   回归和关联检验   |
|         Sign test         |       T-test       |
|      Kruskal–Wallis       |       ANOVA        |
|          ANOSIM           |       MANOVA       |
|  Wilcoxon Rank-Sum test   | Independent t-test |
| Wilcoxon Signed-rank test |   Paired t-test    |



##### 3.6 Python代码实战（见DataWhale参考资料）

* 正态检验

* 卡方检验

* T-test

* ANOVA

* Mann-Whitney U test