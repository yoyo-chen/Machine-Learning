参考资料
[DataWhale 组队学习/数据挖掘基础方法/概率统计/2. 数理统计与描述性统计](https://github.com/datawhalechina/team-learning/blob/master/02%20%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%9F%BA%E7%A1%80%E6%96%B9%E6%B3%95/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/2.%20%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E4%B8%8E%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1.md)

#### 理论部分

##### 1. 数理统计的概念
* 数理统计使用概率论和数学的方法，研究怎样收集（通过试验或观察）带有随机误差的数据，并在设定的模型（称为统计模型）之下，对这种数据进行分析（称为统计分析），以对所研究的问题作出推断（称为统计推断）。

  描述统计：获取样本，分析样本数据特征。

  推断统计：根据样本推断总体数据的特征。

###### 1.1 基本概念
* 总体的本质是一个概率分布。

  【例1 看得见摸得着的总体】研究某工厂生产的一批元件的使用寿命长短。总体为该批次所有元件的使用寿命，个体为单个元件的使用寿命。

  【例2 想象中的总体】一个物体的真实重量a未知，要通过多次测量的结果去估计它。总体是一切可能的测量结果，个体为单次测量结果。

* 抽样方式的影响

  有放回抽样，一次抽出1个样本，每个样本的分布等同于总体分布。

  无放回或一次抽出多个样本，每个样本的分布不等同于总体分布，但当总体很大或无限时可忽略。

* 样本的两重性：一组随机变量$X_1,X_2,...,X_n$，一组观测值$x_1,x_2,...,x_n$

###### 1.2 统计量与抽样分布
* 完全由样本所决定的量，叫做统计量。统计量是一种“加工”，把样本中所含的某一方面的信息集中起来。
* 统计量的分布为抽样分布

###### 1.3 常用统计量
* 样本均值

$$
\overline X =  \frac{1} {n} {\sum_{i=1}^{n}X_i}
$$

* 样本方差

$$
S^2 =  \frac{1} {n-1} {\sum_{i=1}^{n}(X_i-\overline X)^2}
$$

* **k阶样本原点矩**

$$
A_k =  \frac{1} {n} {\sum_{i=1}^{n}X_i^k}
$$

* **k阶样本中心矩**

$$
M_k =  \frac{1} {n} {\sum_{i=1}^{n}(X_i-\overline X)^k}
$$

==疑问：为什么原点矩和中心距除的是$n$？==

* 顺序统计量

$$
x_{（1）}<=x_{（2）}<=...<=x_{（n）}
$$

##### 2. 描述性统计
###### 2.1 数据集中趋势的度量
* 平均数 $\overline x$
  $$
  \overline x =  \frac{1} {n} {\sum_{i=1}^{n}x_i}
  $$
  
* 中位数 $m_{e}$

* 频数

* 众数

* 比较

|       |               优点                         |    缺点       |
| :---: | :------------------------------------------: | :-----------: |
|  均值  |       充分利用所有数据，适用性强              | 容易受极端值影响 |
| 中位数 |             不受极端值影响                  |    缺乏敏感性    |
|  众数  | 不受极端值影响；当数据具有明显的集中趋势时，代表性好 |    缺乏唯一性    |

* **百分位数** $m_{p}$   0.5分位数（50th百分位数）=中位数

###### 2.2 数据离散趋势的度量
* 方差 $s^2$
  $$
  s^2 =  \frac{1} {n-1} {\sum_{i=1}^{n}(x_i-\overline x)^2}
  $$
  
* 标准差 $s$
  $$
  s=\sqrt{s^2}
  $$
  
* **极差**
$$
R = x_{（n）}-x_{（1）} = max(x)-min(x)
$$
* **变异系数** 

  消除尺度和量纲的影响
$$
{\rm CV} = 100*\frac{s}{\overline x}(\%)
$$
* **四分位差**

  75th百分位与25th百分位数的差值。

  
  $$
  R_1 = Q_3-Q_1
  $$
  
* 四分位差反映了数据的集中程度，该值越小，表示数据越集中于中位数附近，该值越大，表示数据越发散于两端。

* 和中位数一样，不受极端值影响，稳健性好。

###### 2.3 分布特征
* 离散变量与连续变量
* 概率函数
* 分布函数（概率累积函数）
* 正态分布（高斯分布）

###### 2.6 偏度与峰度
* **偏度(skewness)**

  衡量实数随机变量概率分布的不对称性。

  【计算公式】
$$
  Skew(X)=E[(\frac{X-\mu}\sigma)^3] = \frac{\mu_3}{\sigma^3}
$$
  
  $$
  \mu_3 =  \frac{1} {n} {\sum_{i=1}^{n}(X_i-\mu)^3}
  $$

  【理解】
  
  偏度 > 0 $\Rightarrow$  右偏分布，正偏分布，函数曲线右侧“尾巴”更厚。

  （从3阶中心距$\mu_3$的计算公式可以看出，若$X$的取值在概率上大于均值的更多，则$\mu_3$大于0）
  
  偏度 = 0 $\Rightarrow$  正态分布，函数曲线左右对称。
  
  偏度 < 0 $\Rightarrow$  左偏分布，负偏分布，函数曲线左侧“尾巴”更厚。
  
  （从3阶中心距$\mu_3$的计算公式可以看出，若$X$的取值在概率上小于均值的更多，则$\mu_3$小于0）
  
  其他计算公式，例如==（样本数据的计算公式？）==
  $$
  Skew(X)=\frac{n^2M_3}{(n-1)(n-2)s^3}
  $$
  <font color=blue>注：偏度和峰度的计算公式中，$\mu$ , $\sigma$ , $\mu_k$ 表示总体的均值，标准差，$k$阶中心距。$M_k$表示样本的$k$阶中心距，公式见上文。</font>
  
* **峰度(kurtosis)**

  衡量实数随机变量概率分布的峰态。

  【计算公式】
$$
  Kurt(X)=E[(\frac{X-\mu}{\sigma})^4] = \frac{\mu_4}{\sigma^4}
  $$
  
  $$
\mu_4 =  \frac{1} {n} {\sum_{i=1}^{n}(X_i-\mu)^4}
  $$
  
  【理解】

  峰度越小，意味着分布越陡。
  
  （从4阶中心距$\mu_4$的计算公式可以看出，若$X$取值在概率上很集中在均值附近，则$\mu_4$倾向于小，否则就倾向于大。）
  
  “峰度”这个名词，单从表面上看，易引起误解。两个变量$X,Y$谁的峰度大，不能直接比其密度函数的“高峰”陡峭程度，而要调整到方差为1后再去比。此外，并不是峰度值越大，“高峰”处越陡峭，而是恰恰相反。网上不少地方都写错了。
  
  正态分布的峰度 = 3
  
  超值峰度（excess kurtosis）（正态分布峰度为0）
  $$
  Kurt(X)= \frac{\mu_4}{\sigma^4}-3
  $$
  其他计算公式，例如
  $$
  Kurt(X)= \frac{n^2(n+1)M_4}{(n-1)(n-2)(n-3)s^4}-3\frac{(n-1)^2}{(n-2)(n-3)}
  $$
  



#### 给猫猫开的小灶

* **无偏估计 有偏估计**

  **无偏**：由样本得出的估计量围绕目标（总体特征）上下波动

  **有偏**：由样本得出的估计量偏离目标（总体特征）

  【例1】无偏估计量：用样本均值$\overline X$估计总体均值$\mu$ ，用$S_1^2=\frac{1}{n}\sum(X_i-\mu)^2$估计总体方差$\sigma^2=E[(X-\mu)^2]$

  【例2】有偏估计量：用$S_2^2=\frac{1}{n}\sum(X_i-\overline X)^2$估计总体方差$\sigma^2$

  ​            因为方差的计算中有平方，样本均值不等于总体均值，这导致$S_2^2$总是小于$S_1^2$。总体方差被低估，低估了$\frac{1}{n}\sigma^2$ [推导过程](https://www.matongxue.com/madocs/607.html)

  【例3】无偏估计量：用$S^2=\frac{1}{n-1}\sum(X_i-\overline X)^2$估计总体方差$\sigma^2$ [为什么是n-1看这里](https://www.matongxue.com/madocs/607.html)

  

* **有效性 一致性**

  **有效性**：估计量越靠近目标，有效性越高。方差越小，有效性越高。

  **一致性**：随着采样个数$n$增加，估计量的偏差值越来越小，那么这个估计就是“一致”的。

  【例】方差$S_2^2$的偏差值为$\frac{1}{n}\sigma^2$ ，这个值随着$n$的增加会越来越小，所以说$S_2^2$是“一致”的。)

  <font color=blue>注：选择估计量时，不一定非要选无偏估计量，有效性也很重要。如果样本数够多，那么“有偏”但是“一致”的估计量也可以选。</font>



#### 练习部分

###### python实现数据各维度的描述性分析
参考资料

[numpy教程：统计函数Statistics](https://blog.csdn.net/pipisorry/article/details/48770785)

[使用Python进行描述性统计 ](https://www.cnblogs.com/jasonfreak/p/5441512.html)

* 平均数，中位数，众数，百分位数，频数，四分位差，极差

```python
#NumPy系统是Python的一种开源的数值计算扩展。用来存储和处理大型矩阵。
import numpy as np 
a = [1,2,4,5,3,12,12,23,43,52,11,22,22,22]
a_mean = np.mean(a)  #均值
a_med = np.median(a)  #中位数
a_m75 = np.percentile(a,75) # 75th百分位数
Cnt_22 = a.count(22) # 频数
a_R1 = np.percentile(a,75)-np.percentile(a,25) # 四分位差
a_R = np.amax(a)-np.amin(a) #极差
print("a的平均数:",a_mean)
print("a的中位数:",a_med)
print("a的75th百分位数:",a_m75)
print("a中22的频数",Cnt_22)
print("a的四分位差:",a_R1)
print("a的极差",a_R)
#------------------------------------------------------------
from scipy import stats   
'''
Scipy是一个高级的科学计算库，Scipy一般都是操控Numpy数组来进行科学计算，
Scipy包含的功能有最优化、线性代数、积分、插值、拟合、特殊函数、快速傅里叶变换、
信号处理和图像处理、常微分方程求解和其他科学与工程中常用的计算。
'''
a_m1 =stats.mode(a)[0][0]
print("a的众数:",a_m1)
#-------------------------------------------------------------
import pandas as pd
'''
Pandas是基于NumPy的一个数据分析包，是为了解决数据分析任务而创建的。
Pandas纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。
pandas提供了大量能使我们快速便捷地处理数据的函数和方法。
你很快就会发现，它是使Python成为强大而高效的数据分析环境的重要因素之一。
'''
#将一维数组转成Pandas的Series，然后调用Pandas的mode()方法
ser = pd.Series(a)
a_m2 = ser.mode()
print("a的众数:",a_m2)
```



* 方差，标准差，变异系数

```python
import numpy as np 
a = [1,2,4,5,3,12,12,23,43,52,11,22,22,22]
a_var = np.var(a)  #方差 有偏
a_std1 = np.sqrt(a_var) #标准差 有偏
a_std2 = np.std(a) #标准差 有偏
a_mean = np.mean(a)  #均值
a_cv =  a_std2 /a_mean #变异系数
print("a的方差:",a_var)
print("a的标准差:",a_std1)
print("a的标准差:",a_std2)
print("a的变异系数:",a_cv)
```



* 生成标准正态分布，偏度系数，峰度系数

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
data = list(np.random.randn(10000))
#生成标准正态分布的随机数（10000个）
plt.hist(data,1000,facecolor='g',alpha=0.5)
'''
plt.hist(arr, bins=10, facecolor, edgecolor,alpha，histtype='bar')
bins：直方图的柱数，可选项，默认为10
alpha: 透明度
'''
plt.show()
s = pd.Series(data) #将数组转化为序列
print('偏度系数',s.skew())
print('峰度系数',s.kurt()) #超值峰度
```

